{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "TCSKskhH7mM0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Preprocessed Data\n",
        "features = pd.read_csv(\"elliptic_txs_features.csv\", header=None)\n",
        "classes = pd.read_csv(\"elliptic_txs_classes.csv\")"
      ],
      "metadata": {
        "id": "CpYHYR_87mgj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing (as per original notebook)\n",
        "classes['class'] = classes['class'].map({'unknown': -1, '1': 1, '2': 0})  # 1=Illicit, 0=Licit\n",
        "filtered_data = classes[classes['class'] != -1]\n",
        "\n",
        "features = features.iloc[:, 1:]  # Drop transaction ID\n",
        "features = features.loc[filtered_data.index]\n",
        "labels = filtered_data['class']\n"
      ],
      "metadata": {
        "id": "6JM8993K9eHG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n"
      ],
      "metadata": {
        "id": "Nzjs0PX59hy9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8Yvl1kT89jvJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLP Model with explicit input layer\n",
        "input_layer = Input(shape=(X_train_scaled.shape[1],))  # Define input layer\n",
        "x = Dense(128, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dense(8, activation='relu')(x)\n",
        "output_layer = Dense(2, activation='softmax')(x)  # Binary classification (0=Licit, 1=Illicit)\n"
      ],
      "metadata": {
        "id": "aAS1vAaI9lXa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = Model(inputs=input_layer, outputs=output_layer)  # Create the model\n"
      ],
      "metadata": {
        "id": "eGLpzrTx9n5l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train MLP (Ensure Model is Called Before Extracting Embeddings)\n",
        "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Add this line to compile the model\n",
        "mlp_model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# Perform a forward pass to initialize the model (IMPORTANT FIX)\n",
        "_ = mlp_model.predict(X_train_scaled[:1]) # This line ensures the model is called and the input attribute is defined."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksyh04RU9qjU",
        "outputId": "5c559db4-a193-465b-a970-c2f3e3c3127c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.1864 - val_accuracy: 0.9720 - val_loss: 0.0950\n",
            "Epoch 2/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.0987 - val_accuracy: 0.9735 - val_loss: 0.0856\n",
            "Epoch 3/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0867 - val_accuracy: 0.9758 - val_loss: 0.0804\n",
            "Epoch 4/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0799 - val_accuracy: 0.9768 - val_loss: 0.0762\n",
            "Epoch 5/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0769 - val_accuracy: 0.9791 - val_loss: 0.0716\n",
            "Epoch 6/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0694 - val_accuracy: 0.9785 - val_loss: 0.0718\n",
            "Epoch 7/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0650 - val_accuracy: 0.9795 - val_loss: 0.0699\n",
            "Epoch 8/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0640 - val_accuracy: 0.9788 - val_loss: 0.0734\n",
            "Epoch 9/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0629 - val_accuracy: 0.9804 - val_loss: 0.0692\n",
            "Epoch 10/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0577 - val_accuracy: 0.9795 - val_loss: 0.0699\n",
            "Epoch 11/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0585 - val_accuracy: 0.9806 - val_loss: 0.0691\n",
            "Epoch 12/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0583 - val_accuracy: 0.9813 - val_loss: 0.0678\n",
            "Epoch 13/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0543 - val_accuracy: 0.9799 - val_loss: 0.0686\n",
            "Epoch 14/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0580 - val_accuracy: 0.9814 - val_loss: 0.0682\n",
            "Epoch 15/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0504 - val_accuracy: 0.9815 - val_loss: 0.0624\n",
            "Epoch 16/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0518 - val_accuracy: 0.9815 - val_loss: 0.0659\n",
            "Epoch 17/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0520 - val_accuracy: 0.9820 - val_loss: 0.0680\n",
            "Epoch 18/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0523 - val_accuracy: 0.9815 - val_loss: 0.0750\n",
            "Epoch 19/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0531 - val_accuracy: 0.9808 - val_loss: 0.0714\n",
            "Epoch 20/20\n",
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0472 - val_accuracy: 0.9808 - val_loss: 0.0670\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract MLP Embeddings (Intermediate Layer Output)\n",
        "intermediate_layer_model = tf.keras.Model(inputs=mlp_model.input, outputs=mlp_model.layers[-3].output)\n",
        "X_train_embedded = intermediate_layer_model.predict(X_train_scaled)\n",
        "X_test_embedded = intermediate_layer_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcQqIqfG9syU",
        "outputId": "2edde879-f0db-48d4-a7f5-d41adf6f872a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression on MLP Embeddings\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train_embedded, y_train)\n",
        "y_pred = logreg.predict(X_test_embedded)"
      ],
      "metadata": {
        "id": "ZrEdmUpo-DdG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Micro Average F1-Score\n",
        "m_f1 = f1_score(y_test, y_pred, average='micro')"
      ],
      "metadata": {
        "id": "QcI2HOOyKf_P"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Micro Average F1 Score: {m_f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuV4wBikKi7n",
        "outputId": "f9f89675-8b0c-4235-bd0c-ad7b84123dd0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9795\n",
            "Precision: 0.9233\n",
            "Recall: 0.8614\n",
            "F1 Score: 0.8913\n",
            "Micro Average F1 Score: 0.9795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZFpm9oTKsQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
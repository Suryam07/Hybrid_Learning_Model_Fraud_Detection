{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file paths (ensure the files are uploaded to Colab)\n",
        "features_file = \"elliptic_txs_features.csv\"\n",
        "classes_file = \"elliptic_txs_classes.csv\"\n",
        "\n",
        "# Load datasets\n",
        "df_features = pd.read_csv(features_file, header=None)\n",
        "df_classes = pd.read_csv(classes_file)\n",
        "\n",
        "# Display first few rows to verify data\n",
        "print(\"Features Dataset:\")\n",
        "print(df_features.head())\n",
        "\n",
        "print(\"\\nClasses Dataset:\")\n",
        "print(df_classes.head())\n",
        "\n",
        "# Print dataset shapes\n",
        "print(\"\\nFeatures Shape:\", df_features.shape)\n",
        "print(\"Classes Shape:\", df_classes.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSYsSB8tzFj3",
        "outputId": "64a1ee3c-529c-4206-ce31-9a39ef78228f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Dataset:\n",
            "         0    1         2         3         4          5         6    \\\n",
            "0  230425980    1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "1    5530458    1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "2  232022460    1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "3  232438397    1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n",
            "4  230460314    1  1.011523 -0.081127 -1.201369   1.153668  0.333276   \n",
            "\n",
            "        7          8         9    ...       157       158       159       160  \\\n",
            "0 -0.113002  -0.061584 -0.162097  ... -0.562153 -0.600999  1.461330  1.461369   \n",
            "1 -0.113002  -0.061584 -0.162112  ...  0.947382  0.673103 -0.979074 -0.978556   \n",
            "2 -0.113002  -0.061584 -0.162749  ...  0.670883  0.439728 -0.979074 -0.978556   \n",
            "3  9.782742  12.414558 -0.163645  ... -0.577099 -0.613614  0.241128  0.241406   \n",
            "4  1.312656  -0.061584 -0.163523  ... -0.511871 -0.400422  0.517257  0.579382   \n",
            "\n",
            "        161       162       163       164       165       166  \n",
            "0  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
            "1  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
            "2 -0.098889 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
            "3  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
            "4  0.018279  0.277775  0.326394  1.293750  0.178136  0.179117  \n",
            "\n",
            "[5 rows x 167 columns]\n",
            "\n",
            "Classes Dataset:\n",
            "        txId    class\n",
            "0  230425980  unknown\n",
            "1    5530458  unknown\n",
            "2  232022460  unknown\n",
            "3  232438397        2\n",
            "4  230460314  unknown\n",
            "\n",
            "Features Shape: (203769, 167)\n",
            "Classes Shape: (203769, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns in the features dataset\n",
        "df_features.rename(columns={0: \"tx_id\", 1: \"time_step\"}, inplace=True)\n",
        "\n",
        "# Rename columns in the classes dataset\n",
        "df_classes.rename(columns={'txId': 'tx_id', 'class': 'label'}, inplace=True)\n",
        "\n",
        "# Display first few rows after renaming\n",
        "print(\"Renamed Features Dataset:\")\n",
        "print(df_features.head())\n",
        "\n",
        "print(\"\\nRenamed Classes Dataset:\")\n",
        "print(df_classes.head())\n",
        "\n",
        "# Print updated dataset shapes\n",
        "print(\"\\nUpdated Features Shape:\", df_features.shape)\n",
        "print(\"Updated Classes Shape:\", df_classes.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg_e3Er9z0g5",
        "outputId": "319537e6-240a-4f3b-f30b-81ea7058cd3f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed Features Dataset:\n",
            "       tx_id  time_step         2         3         4          5         6  \\\n",
            "0  230425980          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "1    5530458          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "2  232022460          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "3  232438397          1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n",
            "4  230460314          1  1.011523 -0.081127 -1.201369   1.153668  0.333276   \n",
            "\n",
            "          7          8         9  ...       157       158       159       160  \\\n",
            "0 -0.113002  -0.061584 -0.162097  ... -0.562153 -0.600999  1.461330  1.461369   \n",
            "1 -0.113002  -0.061584 -0.162112  ...  0.947382  0.673103 -0.979074 -0.978556   \n",
            "2 -0.113002  -0.061584 -0.162749  ...  0.670883  0.439728 -0.979074 -0.978556   \n",
            "3  9.782742  12.414558 -0.163645  ... -0.577099 -0.613614  0.241128  0.241406   \n",
            "4  1.312656  -0.061584 -0.163523  ... -0.511871 -0.400422  0.517257  0.579382   \n",
            "\n",
            "        161       162       163       164       165       166  \n",
            "0  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
            "1  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
            "2 -0.098889 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
            "3  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
            "4  0.018279  0.277775  0.326394  1.293750  0.178136  0.179117  \n",
            "\n",
            "[5 rows x 167 columns]\n",
            "\n",
            "Renamed Classes Dataset:\n",
            "       tx_id    label\n",
            "0  230425980  unknown\n",
            "1    5530458  unknown\n",
            "2  232022460  unknown\n",
            "3  232438397        2\n",
            "4  230460314  unknown\n",
            "\n",
            "Updated Features Shape: (203769, 167)\n",
            "Updated Classes Shape: (203769, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the features dataset with labels\n",
        "features = df_features.merge(df_classes, on=\"tx_id\", how=\"left\")\n",
        "\n",
        "# Display dataset info after merging\n",
        "print(\"Dataset after merging:\")\n",
        "print(features.head())\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"\\nDataset Shape After Merging:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2EEX_o7zGC7",
        "outputId": "acd239ec-3169-460d-fa77-58a2d3565acc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset after merging:\n",
            "       tx_id  time_step         2         3         4          5         6  \\\n",
            "0  230425980          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "1    5530458          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "2  232022460          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "3  232438397          1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n",
            "4  230460314          1  1.011523 -0.081127 -1.201369   1.153668  0.333276   \n",
            "\n",
            "          7          8         9  ...       158       159       160       161  \\\n",
            "0 -0.113002  -0.061584 -0.162097  ... -0.600999  1.461330  1.461369  0.018279   \n",
            "1 -0.113002  -0.061584 -0.162112  ...  0.673103 -0.979074 -0.978556  0.018279   \n",
            "2 -0.113002  -0.061584 -0.162749  ...  0.439728 -0.979074 -0.978556 -0.098889   \n",
            "3  9.782742  12.414558 -0.163645  ... -0.613614  0.241128  0.241406  1.072793   \n",
            "4  1.312656  -0.061584 -0.163523  ... -0.400422  0.517257  0.579382  0.018279   \n",
            "\n",
            "        162       163       164       165       166    label  \n",
            "0 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  unknown  \n",
            "1 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  unknown  \n",
            "2 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  unknown  \n",
            "3  0.085530 -0.131155  0.677799 -0.120613 -0.119792        2  \n",
            "4  0.277775  0.326394  1.293750  0.178136  0.179117  unknown  \n",
            "\n",
            "[5 rows x 168 columns]\n",
            "\n",
            "Dataset Shape After Merging: (203769, 168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert label column: '1' → 1, '2' → 0, 'unknown' → NaN\n",
        "df_classes[\"label\"] = df_classes[\"label\"].replace({'unknown': np.nan, '1': 1, '2': 0})\n",
        "\n",
        "# Convert to numeric type\n",
        "df_classes[\"label\"] = pd.to_numeric(df_classes[\"label\"])\n",
        "\n",
        "# Verify changes\n",
        "print(\"Updated unique labels in df_classes:\", df_classes[\"label\"].unique())\n",
        "print(\"Label data type after conversion:\", df_classes[\"label\"].dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDwqZwtJzxJs",
        "outputId": "597493bd-1b74-428f-f65e-3d1effa889e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated unique labels in df_classes: [nan  0.  1.]\n",
            "Label data type after conversion: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-6afd97e52bd4>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_classes[\"label\"] = df_classes[\"label\"].replace({'unknown': np.nan, '1': 1, '2': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the features dataset with labels\n",
        "features = df_features.merge(df_classes, on=\"tx_id\", how=\"left\")\n",
        "\n",
        "# Display dataset info after merging\n",
        "print(\"Dataset after merging:\")\n",
        "print(features.head())\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"\\nDataset Shape After Merging:\", features.shape)\n",
        "\n",
        "# Verify label distribution after merging\n",
        "print(\"\\nUnique Labels in Merged Dataset:\", features[\"label\"].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWCo75PG0rJ9",
        "outputId": "7e8fecc5-3feb-4f17-f9e1-28d3b82670d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset after merging:\n",
            "       tx_id  time_step         2         3         4          5         6  \\\n",
            "0  230425980          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "1    5530458          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "2  232022460          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875   \n",
            "3  232438397          1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n",
            "4  230460314          1  1.011523 -0.081127 -1.201369   1.153668  0.333276   \n",
            "\n",
            "          7          8         9  ...       158       159       160       161  \\\n",
            "0 -0.113002  -0.061584 -0.162097  ... -0.600999  1.461330  1.461369  0.018279   \n",
            "1 -0.113002  -0.061584 -0.162112  ...  0.673103 -0.979074 -0.978556  0.018279   \n",
            "2 -0.113002  -0.061584 -0.162749  ...  0.439728 -0.979074 -0.978556 -0.098889   \n",
            "3  9.782742  12.414558 -0.163645  ... -0.613614  0.241128  0.241406  1.072793   \n",
            "4  1.312656  -0.061584 -0.163523  ... -0.400422  0.517257  0.579382  0.018279   \n",
            "\n",
            "        162       163       164       165       166  label  \n",
            "0 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792    NaN  \n",
            "1 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792    NaN  \n",
            "2 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792    NaN  \n",
            "3  0.085530 -0.131155  0.677799 -0.120613 -0.119792    0.0  \n",
            "4  0.277775  0.326394  1.293750  0.178136  0.179117    NaN  \n",
            "\n",
            "[5 rows x 168 columns]\n",
            "\n",
            "Dataset Shape After Merging: (203769, 168)\n",
            "\n",
            "Unique Labels in Merged Dataset: [nan  0.  1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate unknown transactions (for later classification)\n",
        "unknown_transactions = features[features[\"label\"].isna()].copy()\n",
        "\n",
        "# Drop unknown transactions from training data\n",
        "features = features.dropna(subset=[\"label\"])\n",
        "\n",
        "# Convert labels to integer type (avoid float issues)\n",
        "features[\"label\"] = features[\"label\"].astype(int)\n",
        "\n",
        "# Print dataset shapes after filtering\n",
        "print(\"Labeled Dataset Shape (For Training):\", features.shape)\n",
        "print(\"Unknown Transactions Shape (For Later Classification):\", unknown_transactions.shape)\n",
        "\n",
        "# Verify unique labels in training dataset\n",
        "print(\"Final Unique Labels in Training Data:\", features[\"label\"].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ursfw4oj1XeA",
        "outputId": "ba81c3de-273f-4c4a-fefb-c00e1eeef830"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled Dataset Shape (For Training): (46564, 168)\n",
            "Unknown Transactions Shape (For Later Classification): (157205, 168)\n",
            "Final Unique Labels in Training Data: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5f758f122013>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  features[\"label\"] = features[\"label\"].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features with Aggregated Data (Full Feature Set)\n",
        "X_aggregated = features.iloc[:, 2:].values  # Excluding tx_id and time_step\n",
        "\n",
        "# Features without Aggregated Data (Only Raw Features)\n",
        "X_no_aggregated = features.iloc[:, 2:94].values  # Only first 93 features\n",
        "\n",
        "# Labels (Binary)\n",
        "y = features[\"label\"].values\n",
        "\n",
        "# Verify feature shapes\n",
        "print(\"X_aggregated Shape:\", X_aggregated.shape)  # Expected: (46564, 166)\n",
        "print(\"X_no_aggregated Shape:\", X_no_aggregated.shape)  # Expected: (46564, 92)\n",
        "print(\"Labels Shape:\", y.shape)  # Expected: (46564,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIdj_QnU1lQj",
        "outputId": "efdee5a3-68a2-463a-8ff0-6af15e30a5ab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_aggregated Shape: (46564, 166)\n",
            "X_no_aggregated Shape: (46564, 92)\n",
            "Labels Shape: (46564,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split Data (With Aggregated Features)\n",
        "X_train_agg, X_test_agg, y_train_agg, y_test_agg = train_test_split(\n",
        "    X_aggregated, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Split Data (Without Aggregated Features)\n",
        "X_train_noagg, X_test_noagg, y_train_noagg, y_test_noagg = train_test_split(\n",
        "    X_no_aggregated, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Print shapes of train and test sets\n",
        "print(\"Train set (Aggregated):\", X_train_agg.shape, y_train_agg.shape)\n",
        "print(\"Test set (Aggregated):\", X_test_agg.shape, y_test_agg.shape)\n",
        "print(\"Train set (No Aggregated):\", X_train_noagg.shape, y_train_noagg.shape)\n",
        "print(\"Test set (No Aggregated):\", X_test_noagg.shape, y_test_noagg.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSR7hJ-M1wsb",
        "outputId": "98d41622-9490-4a4e-b922-96f210363592"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set (Aggregated): (37251, 166) (37251,)\n",
            "Test set (Aggregated): (9313, 166) (9313,)\n",
            "Train set (No Aggregated): (37251, 92) (37251,)\n",
            "Test set (No Aggregated): (9313, 92) (9313,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert Data to PyTorch tensors (Aggregated)\n",
        "X_train_agg_tensor = torch.tensor(X_train_agg, dtype=torch.float32)\n",
        "X_test_agg_tensor = torch.tensor(X_test_agg, dtype=torch.float32)\n",
        "y_train_agg_tensor = torch.tensor(y_train_agg, dtype=torch.long)\n",
        "y_test_agg_tensor = torch.tensor(y_test_agg, dtype=torch.long)\n",
        "\n",
        "# Convert Data to PyTorch tensors (Without Aggregated Features)\n",
        "X_train_noagg_tensor = torch.tensor(X_train_noagg, dtype=torch.float32)\n",
        "X_test_noagg_tensor = torch.tensor(X_test_noagg, dtype=torch.float32)\n",
        "y_train_noagg_tensor = torch.tensor(y_train_noagg, dtype=torch.long)\n",
        "y_test_noagg_tensor = torch.tensor(y_test_noagg, dtype=torch.long)\n",
        "\n",
        "# Print tensor shapes to verify\n",
        "print(\"Train set (Aggregated):\", X_train_agg_tensor.shape, y_train_agg_tensor.shape)\n",
        "print(\"Test set (Aggregated):\", X_test_agg_tensor.shape, y_test_agg_tensor.shape)\n",
        "print(\"Train set (No Aggregated):\", X_train_noagg_tensor.shape, y_train_noagg_tensor.shape)\n",
        "print(\"Test set (No Aggregated):\", X_test_noagg_tensor.shape, y_test_noagg_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p19EdK8Z19sp",
        "outputId": "a718a3f1-146e-403e-e47f-a2dd81054bc6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set (Aggregated): torch.Size([37251, 166]) torch.Size([37251])\n",
            "Test set (Aggregated): torch.Size([9313, 166]) torch.Size([9313])\n",
            "Train set (No Aggregated): torch.Size([37251, 92]) torch.Size([37251])\n",
            "Test set (No Aggregated): torch.Size([9313, 92]) torch.Size([9313])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DNNClassifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DNNClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "        self.out = nn.Linear(32, 2)  # Binary classification (Licit vs Illicit)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.out(x)  # No softmax (CrossEntropyLoss applies it internally)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yYBzSNvd2Jgw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define training parameters\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define loss function (CrossEntropyLoss for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer (Adam for better convergence)\n",
        "def get_optimizer(model):\n",
        "    return optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "R4TMgtOx2XVE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, y_train, X_test, y_test, num_epochs=50):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
        "    model.to(device)\n",
        "\n",
        "    # Convert data to device (CPU/GPU)\n",
        "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "    X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set to training mode\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:  # Print every 10 epochs\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_outputs = model(X_test)\n",
        "                test_loss = criterion(test_outputs, y_test)\n",
        "\n",
        "                print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "    print(\"Training Complete!\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "XDNzovwN2cop"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model for aggregated features\n",
        "model_agg = DNNClassifier(input_dim=X_train_agg_tensor.shape[1])\n",
        "\n",
        "# Train the model\n",
        "model_agg = train_model(model_agg, X_train_agg_tensor, y_train_agg_tensor, X_test_agg_tensor, y_test_agg_tensor, num_epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wuzy94Wp2h_W",
        "outputId": "fbb48772-a79c-4086-84fc-73273287c4ec"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50, Train Loss: 0.8519, Test Loss: 0.7069\n",
            "Epoch 10/50, Train Loss: 0.6031, Test Loss: 0.6442\n",
            "Epoch 20/50, Train Loss: 0.4614, Test Loss: 0.5425\n",
            "Epoch 30/50, Train Loss: 0.3744, Test Loss: 0.4249\n",
            "Epoch 40/50, Train Loss: 0.3120, Test Loss: 0.3310\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model_agg.eval()\n",
        "\n",
        "# Move data to device (CPU/GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_test_agg_tensor, y_test_agg_tensor = X_test_agg_tensor.to(device), y_test_agg_tensor.to(device)\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_agg(X_test_agg_tensor)\n",
        "    _, y_pred_agg = torch.max(test_outputs, 1)  # Convert logits to class predictions\n",
        "\n",
        "# Convert tensors to numpy arrays\n",
        "y_pred_agg = y_pred_agg.cpu().numpy()\n",
        "y_test_agg = y_test_agg_tensor.cpu().numpy()\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy_agg = accuracy_score(y_test_agg, y_pred_agg)\n",
        "precision_agg = precision_score(y_test_agg, y_pred_agg)\n",
        "recall_agg = recall_score(y_test_agg, y_pred_agg)\n",
        "f1_agg = f1_score(y_test_agg, y_pred_agg)\n",
        "\n",
        "# Print results\n",
        "print(\"DNN Evaluation on Aggregated Features:\")\n",
        "print(f\"Accuracy: {accuracy_agg:.4f}\")\n",
        "print(f\"Precision: {precision_agg:.4f}\")\n",
        "print(f\"Recall: {recall_agg:.4f}\")\n",
        "print(f\"F1 Score: {f1_agg:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn6tL33O2o0x",
        "outputId": "5bc215f5-59b6-443c-b3ff-4cbd6f37eb68"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN Evaluation on Aggregated Features:\n",
            "Accuracy: 0.9622\n",
            "Precision: 0.7979\n",
            "Recall: 0.8207\n",
            "F1 Score: 0.8091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model for non-aggregated features\n",
        "model_noagg = DNNClassifier(input_dim=X_train_noagg_tensor.shape[1])\n",
        "\n",
        "# Train the model\n",
        "model_noagg = train_model(model_noagg, X_train_noagg_tensor, y_train_noagg_tensor, X_test_noagg_tensor, y_test_noagg_tensor, num_epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYE6mrEW2yoY",
        "outputId": "78a99d42-1307-4ade-c341-d968320b2193"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50, Train Loss: 0.9967, Test Loss: 0.7862\n",
            "Epoch 10/50, Train Loss: 0.7363, Test Loss: 0.7140\n",
            "Epoch 20/50, Train Loss: 0.6058, Test Loss: 0.6513\n",
            "Epoch 30/50, Train Loss: 0.5164, Test Loss: 0.5440\n",
            "Epoch 40/50, Train Loss: 0.4351, Test Loss: 0.4557\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model_noagg.eval()\n",
        "\n",
        "# Move data to device (CPU/GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_test_noagg_tensor, y_test_noagg_tensor = X_test_noagg_tensor.to(device), y_test_noagg_tensor.to(device)\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_noagg(X_test_noagg_tensor)\n",
        "    _, y_pred_noagg = torch.max(test_outputs, 1)  # Convert logits to class predictions\n",
        "\n",
        "# Convert tensors to numpy arrays\n",
        "y_pred_noagg = y_pred_noagg.cpu().numpy()\n",
        "y_test_noagg = y_test_noagg_tensor.cpu().numpy()\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy_noagg = accuracy_score(y_test_noagg, y_pred_noagg)\n",
        "precision_noagg = precision_score(y_test_noagg, y_pred_noagg)\n",
        "recall_noagg = recall_score(y_test_noagg, y_pred_noagg)\n",
        "f1_noagg = f1_score(y_test_noagg, y_pred_noagg)\n",
        "\n",
        "# Print results\n",
        "print(\"DNN Evaluation on Non-Aggregated Features:\")\n",
        "print(f\"Accuracy: {accuracy_noagg:.4f}\")\n",
        "print(f\"Precision: {precision_noagg:.4f}\")\n",
        "print(f\"Recall: {recall_noagg:.4f}\")\n",
        "print(f\"F1 Score: {f1_noagg:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg-ddx9v3EpR",
        "outputId": "4f99934e-d446-4035-d5fa-2307462f2aaf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN Evaluation on Non-Aggregated Features:\n",
            "Accuracy: 0.9414\n",
            "Precision: 0.7189\n",
            "Recall: 0.6557\n",
            "F1 Score: 0.6858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_9z5IR63RB9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}